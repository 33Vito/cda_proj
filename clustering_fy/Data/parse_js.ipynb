{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pickle\n",
    "import matplotlib.pyplot as pl\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(val):\n",
    "    \"\"\"Convert a value to numeric if it is.\"\"\"\n",
    "    val = val.replace(',', '')\n",
    "    val = float(val) if val.isdigit() else val\n",
    "    return val\n",
    "\n",
    "def get_values_2006(table):\n",
    "    \"\"\"Parse table for 2006 html page.\"\"\"\n",
    "    # find values\n",
    "    values = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        if row.find('td') is None:\n",
    "            continue\n",
    "        record = [row.find_all('td')[0].text]\n",
    "        records = record + [convert(x.text) for x in row.find_all('td')[1:]]\n",
    "        if len(records) == 1:\n",
    "            continue\n",
    "        values.append(records)\n",
    "    return values\n",
    "\n",
    "def get_values_2016(table):\n",
    "    \"\"\"Parse table for 2016 html page.\"\"\"\n",
    "    # find values\n",
    "    values = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        if row.find('td') is None:\n",
    "            continue\n",
    "        record = [row.find_all('th')[0].text]\n",
    "        records = record + [convert(x.text) for x in row.find_all('td')]\n",
    "        values.append(records)\n",
    "    return values\n",
    "\n",
    "def parse_common_table(table, year):\n",
    "    \"\"\"Parse table that has common row names across different suburbs.\"\"\"\n",
    "    # find column names\n",
    "    row = table.find_all('tr')[0]\n",
    "    columns = [x.text for x in row.find_all('th')]\n",
    "    for i, x in enumerate(columns):\n",
    "        if x == '%':\n",
    "            columns[i] = columns[i - 1] + \" (%)\"\n",
    "    \n",
    "    if year != '2016':\n",
    "        values = get_values_2006(table)\n",
    "    else:\n",
    "        values = get_values_2016(table)\n",
    "    \n",
    "    data = pd.DataFrame(values, columns=columns).T\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.iloc[1:]\n",
    "\n",
    "    # create double columns for percentage\n",
    "    columns = list(data.columns)\n",
    "    newcolumns = [x + ' (%)' for x in columns]\n",
    "    for x in newcolumns:\n",
    "        data[x] = None\n",
    "        \n",
    "    # find percentage rows and fill in value\n",
    "    index = [x for x in data.index if '%' in x]\n",
    "    for i in index:\n",
    "        record = data.loc[i]\n",
    "        rowname = ' '.join(i.split(' ')[:-1])\n",
    "        for x in columns:\n",
    "            data.at[rowname, x + ' (%)'] =  record[x]\n",
    "    \n",
    "    # drop those rows\n",
    "    data = data.drop(index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_map = {}\n",
    "uncommon_map = {}\n",
    "\n",
    "for year in ['2001', '2006', '2011', '2016']:\n",
    "    with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    soup = bs(d['Burwood'], 'html')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    cmap = {}\n",
    "    ucmap = {}\n",
    "    for i, tb in enumerate(tables):\n",
    "        try:\n",
    "            z = re.search(r'(\\<\\!--).+(-->)', str(tb))\n",
    "            name = z.group().replace('<!-- ', '').replace('-->', '').strip()\n",
    "        except AttributeError:\n",
    "            name = tb.text.strip().split('\\n')[0]\n",
    "        try:\n",
    "            df = parse_common_table(tb, year)\n",
    "            if len(df.columns) <= 1:\n",
    "                ucmap[i] = name\n",
    "            else:\n",
    "                cmap[i] = name\n",
    "        except:\n",
    "            cmap[i] = name\n",
    "    # append to overall mapping\n",
    "    common_map[year] = cmap\n",
    "    uncommon_map[year] = ucmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2001': {9: 'Religious affiliation, top responses',\n",
       "  10: 'Language, top responses (other than English)',\n",
       "  12: 'Occupation',\n",
       "  13: 'Industry of employment, top responses',\n",
       "  8: 'Country of birth'},\n",
       " '2006': {9: 'Religious affiliation, top responses',\n",
       "  10: 'Language, top responses (other than English)',\n",
       "  12: 'Occupation',\n",
       "  13: 'Industry of employment, top responses',\n",
       "  21: 'Household composition',\n",
       "  8: 'Country of birth'},\n",
       " '2011': {11: 'Ancestry, top responses',\n",
       "  14: 'Religious affiliation, top responses',\n",
       "  15: 'Language, top responses (other than English)',\n",
       "  19: 'Occupation',\n",
       "  20: 'Industry of employment, top responses',\n",
       "  22: 'Travel to work, top responses',\n",
       "  12: 'Country of birth'},\n",
       " '2016': {9: 'Ancestry, top responses',\n",
       "  12: 'Country of birth of father',\n",
       "  13: 'Country of birth of mother',\n",
       "  14: 'Religious affiliation',\n",
       "  15: 'Language, top responses5',\n",
       "  18: 'Occupation',\n",
       "  19: 'Industry of employment',\n",
       "  21: 'Travel to work',\n",
       "  10: 'Country of birth'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non2016 = [0, 1, 2, 3, 4]\n",
    "yes2016 = [0, 1, 2, 3]\n",
    "for year in common_map:\n",
    "    exclusion = yes2016 if year == '2016' else non2016\n",
    "    common_map[year] = {k: v for k, v in common_map[year].items() if k not in exclusion and v != ''}\n",
    "    \n",
    "# country of birth should be taken out\n",
    "for year in common_map:\n",
    "    c = common_map[year]\n",
    "    topop = None\n",
    "    for k, v in c.items():\n",
    "        if v == 'Country of birth':\n",
    "            uncommon_map[year][k] = v\n",
    "            topop = k\n",
    "    common_map[year].pop(k)\n",
    "uncommon_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Industry of employment'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = '2016'\n",
    "with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "    source = pickle.load(f)\n",
    "uncommon_map\n",
    "uncommon_map[year]\n",
    "index = 6\n",
    "tablename = list(uncommon_map[year].values())[index]\n",
    "suburb = 'Burwood'\n",
    "\n",
    "soup = bs(source[suburb], 'html')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "tables[index]\n",
    "\n",
    "# find javascript\n",
    "scripts = soup.find_all('script')\n",
    "javascript = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs\n",
    "              and x.attrs['type'] == 'text/javascript'][0]\n",
    "tablename\n",
    "\n",
    "# uncommon_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Social marital statusPeople aged 15 years and over',\n",
       " 'Burwood (NSW)',\n",
       " 'Burwood (NSW) (%)',\n",
       " 'New South Wales',\n",
       " 'New South Wales (%)',\n",
       " 'Australia',\n",
       " 'Australia (%)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = tables[index]\n",
    "# find column names\n",
    "\n",
    "tables[index]\n",
    "\n",
    "# find javascript\n",
    "scripts = soup.find_all('script')\n",
    "javascript = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs\n",
    "              and x.attrs['type'] == 'text/javascript'][0]\n",
    "\n",
    "row = table.find_all('tr')[0]\n",
    "columns = [x.text for x in row.find_all('th')]\n",
    "for i, x in enumerate(columns):\n",
    "    if x == '%':\n",
    "        columns[i] = columns[i - 1] + \" (%)\"\n",
    "        \n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_mapping = {}\n",
    "\n",
    "p2016 = {}\n",
    "for _, k in uncommon_map['2016'].items():\n",
    "    newk = k.split(',')[0]\n",
    "    newk = newk.replace('birth of', '')\n",
    "    newk = newk.replace(' of employment', '')\n",
    "    newk = newk.split(' ')\n",
    "    if len(newk) > 1:\n",
    "        newk[1:] = [x.capitalize() for x in newk[1:]]\n",
    "    newk[0] = newk[0].lower()\n",
    "    newk = ''.join(newk)\n",
    "    p2016[k] = 'var {}Data'.format(newk)\n",
    "\n",
    "pattern_mapping['2016'] = p2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ancestry, top responses</th>\n",
       "      <th>Burwood (%)</th>\n",
       "      <th>New South Wales (%)</th>\n",
       "      <th>Australia (%)</th>\n",
       "      <th>Burwood</th>\n",
       "      <th>New South Wales</th>\n",
       "      <th>Australia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>45.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8,096</td>\n",
       "      <td>514,594</td>\n",
       "      <td>1,213,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1,248</td>\n",
       "      <td>2,302,481</td>\n",
       "      <td>7,852,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>944</td>\n",
       "      <td>2,261,062</td>\n",
       "      <td>7,298,243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>694</td>\n",
       "      <td>211,927</td>\n",
       "      <td>619,164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Korean</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>667</td>\n",
       "      <td>66,613</td>\n",
       "      <td>123,017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ancestry, top responses Burwood (%) New South Wales (%) Australia (%)  \\\n",
       "0                 Chinese        45.1                 5.2           3.9   \n",
       "0                 English         7.0                23.3          25.0   \n",
       "0              Australian         5.3                22.9          23.3   \n",
       "0                  Indian         3.9                 2.1           2.0   \n",
       "0                  Korean         3.7                 0.7           0.4   \n",
       "\n",
       "  Burwood New South Wales  Australia  \n",
       "0   8,096         514,594  1,213,903  \n",
       "0   1,248       2,302,481  7,852,224  \n",
       "0     944       2,261,062  7,298,243  \n",
       "0     694         211,927    619,164  \n",
       "0     667          66,613    123,017  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "var = list(p2016.values())[i]\n",
    "original_name = list(uncommon_map['2016'].values())[i]\n",
    "get_vardata(var, javascript, original_name, 'Burwood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Javascript Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year=2016 Table=Ancestry, top responses\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=9\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=9\n",
      "  Error with Long Point, index=9\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=9\n",
      "  Error with Mayfield, index=9\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=9\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=9\n",
      "  Error with St Clair, index=9\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Ancestry_top_responses.csv\n",
      "Year=2016 Table=Country of birth of father\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=12\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=12\n",
      "  Error with Long Point, index=12\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=12\n",
      "  Error with Mayfield, index=12\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=12\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=12\n",
      "  Error with St Clair, index=12\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Country_of_birth_of_father.csv\n",
      "Year=2016 Table=Country of birth of mother\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=13\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=13\n",
      "  Error with Long Point, index=13\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=13\n",
      "  Error with Mayfield, index=13\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=13\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=13\n",
      "  Error with St Clair, index=13\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Country_of_birth_of_mother.csv\n",
      "Year=2016 Table=Religious affiliation\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=14\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=14\n",
      "  Error with Long Point, index=14\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=14\n",
      "  Error with Mayfield, index=14\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=14\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=14\n",
      "  Error with St Clair, index=14\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Religious_affiliation.csv\n",
      "Year=2016 Table=Language, top responses5\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=15\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=15\n",
      "  Error with Long Point, index=15\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=15\n",
      "  Error with Mayfield, index=15\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=15\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=15\n",
      "  Error with St Clair, index=15\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Language_top_responses5.csv\n",
      "Year=2016 Table=Occupation\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=18\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=18\n",
      "  Error with Long Point, index=18\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=18\n",
      "  Error with Mayfield, index=18\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=18\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=18\n",
      "  Error with St Clair, index=18\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Occupation.csv\n",
      "Year=2016 Table=Industry of employment\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=19\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=19\n",
      "  Error with Long Point, index=19\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=19\n",
      "  Error with Mayfield, index=19\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=19\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=19\n",
      "  Error with St Clair, index=19\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Industry_of_employment.csv\n",
      "Year=2016 Table=Travel to work\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "  Error with Dural, index=21\n",
      "    Iteration i=300\n",
      "  Error with Hillsborough, index=21\n",
      "  Error with Long Point, index=21\n",
      "    Iteration i=400\n",
      "  Error with Maryland, index=21\n",
      "  Error with Mayfield, index=21\n",
      "    Iteration i=500\n",
      "  Error with Punchbowl, index=21\n",
      "    Iteration i=600\n",
      "  Error with Springfield, index=21\n",
      "  Error with St Clair, index=21\n",
      "    Iteration i=700\n",
      "Saving to census_data/2016_Travel_to_work.csv\n",
      "Year=2016 Table=Country of birth\n"
     ]
    }
   ],
   "source": [
    "year = '2016'\n",
    "dataroot = 'census_data'\n",
    "\n",
    "with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "    source = pickle.load(f)\n",
    "\n",
    "# iterate all common tables\n",
    "for index, tablename in uncommon_map[year].items():\n",
    "    name = '{}_{}.csv'.format(year, tablename).replace(' ', '_').replace(',', '')\n",
    "    name = name.replace('/', '_')\n",
    "    path = os.path.join(dataroot, name)\n",
    "    print('Year={} Table={}'.format(year, tablename))\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    group = []\n",
    "    for i, (suburb, txt) in enumerate(source.items()):\n",
    "        if i % 100 == 0:\n",
    "            print('    Iteration i={}'.format(i))\n",
    "        soup = bs(txt, 'html')\n",
    "        try:\n",
    "            var = pattern_mapping[year][tablename]\n",
    "            sdata = parse_uncommon_table(soup, var, tablename, suburb)\n",
    "            group.append(sdata)\n",
    "        except IndexError:\n",
    "            print('  Error with {}, index={}'.format(suburb, index))\n",
    "            continue\n",
    "    data = parse_uncommon_allsuburbs(group)\n",
    "    print('Saving to', path)\n",
    "    data.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_uncommon_allsuburbs(group):\n",
    "    \"\"\"Parse uncommon table of all suburbs in group.\"\"\"\n",
    "    # drop NSW and Australia in 1: tables\n",
    "    for i, df in enumerate(group):\n",
    "        if i > 0:\n",
    "            df = df.drop(['New South Wales (%)', 'Australia (%)', 'New South Wales', 'Australia'], axis=1)\n",
    "            group[i] = df\n",
    "    # outer join all dataframes\n",
    "    key = group[0].columns[0]\n",
    "    data = pd.merge(group[0], group[1], how='outer', on=key)\n",
    "    for i in range(2, len(group)):\n",
    "        data = pd.merge(data, group[i], how='outer', on=key)\n",
    "    \n",
    "    # transpose and set column names\n",
    "    data = data.T\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.iloc[1:]\n",
    "\n",
    "    # create double columns for percentage\n",
    "    columns = list(data.columns)\n",
    "    newcolumns = [x + ' (%)' for x in columns]\n",
    "    for x in newcolumns:\n",
    "        data[x] = None\n",
    "\n",
    "    # find percentage rows and fill in value\n",
    "    index = [x for x in data.index if '%' in x]\n",
    "    for i in index:\n",
    "        record = data.loc[i]\n",
    "        rowname = ' '.join(i.split(' ')[:-1])\n",
    "        for x in columns:\n",
    "            data.at[rowname, x + ' (%)'] =  record[x]\n",
    "\n",
    "    # drop those rows\n",
    "    data = data.drop(index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ancestry, top responses</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Chinese (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hurstville</th>\n",
       "      <td>16,403</td>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burwood</th>\n",
       "      <td>8,096</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhodes</th>\n",
       "      <td>5,848</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastwood</th>\n",
       "      <td>8,071</td>\n",
       "      <td>38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ultimo</th>\n",
       "      <td>3,709</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East Killara</th>\n",
       "      <td>1,286</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chatswood</th>\n",
       "      <td>10,102</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zetland</th>\n",
       "      <td>4,116</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chippendale</th>\n",
       "      <td>3,406</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carlingford</th>\n",
       "      <td>9,302</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haymarket</th>\n",
       "      <td>2,556</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campsie</th>\n",
       "      <td>8,550</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epping</th>\n",
       "      <td>8,834</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berala</th>\n",
       "      <td>3,104</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kingsford</th>\n",
       "      <td>5,557</td>\n",
       "      <td>29.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allawah</th>\n",
       "      <td>1,954</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Narwee</th>\n",
       "      <td>1,968</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marsfield</th>\n",
       "      <td>4,638</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Hurstville</th>\n",
       "      <td>1,693</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riverwood</th>\n",
       "      <td>3,893</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beverly Hills</th>\n",
       "      <td>3,242</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homebush West</th>\n",
       "      <td>2,429</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denistone East</th>\n",
       "      <td>686</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney</th>\n",
       "      <td>4,851</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabramatta</th>\n",
       "      <td>6,157</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lidcombe</th>\n",
       "      <td>5,108</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canley Vale</th>\n",
       "      <td>2,684</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kensington</th>\n",
       "      <td>4,053</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meadowbank</th>\n",
       "      <td>1,099</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macquarie Park</th>\n",
       "      <td>2,052</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newington</th>\n",
       "      <td>1,468</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regents Park</th>\n",
       "      <td>1,182</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gordon</th>\n",
       "      <td>2,022</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Penshurst</th>\n",
       "      <td>3,204</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Killara</th>\n",
       "      <td>2,821</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denistone</th>\n",
       "      <td>978</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waitara</th>\n",
       "      <td>1,408</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hurstville Grove</th>\n",
       "      <td>649</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Darlington</th>\n",
       "      <td>805</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strathfield</th>\n",
       "      <td>5,807</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Ryde</th>\n",
       "      <td>3,184</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denistone West</th>\n",
       "      <td>226</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St Leonards</th>\n",
       "      <td>1,314</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burwood Heights</th>\n",
       "      <td>221</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ashfield</th>\n",
       "      <td>5,588</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty Grove</th>\n",
       "      <td>500</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carlton</th>\n",
       "      <td>2,421</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dundas Valley</th>\n",
       "      <td>1,255</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canley Heights</th>\n",
       "      <td>2,434</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dundas</th>\n",
       "      <td>1,084</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ancestry, top responses Chinese  Chinese (%)\n",
       "Hurstville               16,403         49.4\n",
       "Burwood                   8,096         45.1\n",
       "Rhodes                    5,848         44.5\n",
       "Eastwood                  8,071         38.4\n",
       "Ultimo                    3,709         36.6\n",
       "East Killara              1,286         35.9\n",
       "Chatswood                10,102         34.1\n",
       "Zetland                   4,116         33.8\n",
       "Chippendale               3,406         33.1\n",
       "Carlingford               9,302         32.0\n",
       "Haymarket                 2,556         31.9\n",
       "Campsie                   8,550         31.0\n",
       "Epping                    8,834         31.0\n",
       "Berala                    3,104         30.0\n",
       "Kingsford                 5,557         29.6\n",
       "Allawah                   1,954         29.5\n",
       "Narwee                    1,968         29.2\n",
       "Marsfield                 4,638         28.7\n",
       "South Hurstville          1,693         27.5\n",
       "Riverwood                 3,893         27.2\n",
       "Beverly Hills             3,242         26.5\n",
       "Homebush West             2,429         25.5\n",
       "Denistone East              686         24.8\n",
       "Sydney                    4,851         24.6\n",
       "Cabramatta                6,157         24.5\n",
       "Lidcombe                  5,108         23.1\n",
       "Canley Vale               2,684         22.5\n",
       "Kensington                4,053         21.2\n",
       "Meadowbank                1,099         20.8\n",
       "Macquarie Park            2,052         20.8\n",
       "Newington                 1,468         20.6\n",
       "Regents Park              1,182         20.5\n",
       "Gordon                    2,022         20.5\n",
       "Penshurst                 3,204         20.4\n",
       "Killara                   2,821         20.2\n",
       "Denistone                   978         20.1\n",
       "Waitara                   1,408         20.0\n",
       "Hurstville Grove            649         19.8\n",
       "Darlington                  805         19.6\n",
       "Strathfield               5,807         19.6\n",
       "West Ryde                 3,184         19.4\n",
       "Denistone West              226         19.3\n",
       "St Leonards               1,314         19.3\n",
       "Burwood Heights             221         19.2\n",
       "Ashfield                  5,588         19.0\n",
       "Liberty Grove               500         19.0\n",
       "Carlton                   2,421         18.8\n",
       "Dundas Valley             1,255         18.6\n",
       "Canley Heights            2,434         18.6\n",
       "Dundas                    1,084         18.4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese = data[~pd.isnull(data['Chinese'])][['Chinese', 'Chinese (%)']]\n",
    "chinese['Chinese (%)'] = chinese['Chinese (%)'].astype(float)\n",
    "chinese.sort_values('Chinese (%)', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toaddquote = ['categoryField', 'areaPercent', 'statePercent', 'australiaPercent',\n",
    "              'areaValue', 'stateValue', 'australiaValue']\n",
    "toremove = ['QuickStats.formatValue(', ')']\n",
    "\n",
    "def parse_uncommon_table(soup, var, original_name, suburb):\n",
    "    \"\"\"Get JS variable data from HTML.\"\"\"\n",
    "    # find javascript\n",
    "    scripts = soup.find_all('script')\n",
    "    js = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs and x.attrs['type'] == 'text/javascript'][0]\n",
    "    # pattern name\n",
    "    pattern = '(' + var + ' = \\[)[^\\]]*(\\];)'\n",
    "    toreplace = var + ' = ['\n",
    "    m = re.search(pattern, str(js))\n",
    "    j = m.group().replace(toreplace, '').replace('];', '').strip()\n",
    "    j = j.replace('\\n', '').replace('\\t', '')\n",
    "\n",
    "    for val in toaddquote:\n",
    "        j = j.replace(val, '\"{}\"'.format(val))\n",
    "\n",
    "    for val in toremove:\n",
    "        j = j.replace(val, '')\n",
    "\n",
    "    values = j.split('},')\n",
    "    values = [x + '}' for x in values]\n",
    "    values = [x.replace('}}', '}') for x in values]\n",
    "\n",
    "    records = []\n",
    "    for x in values:\n",
    "        dct = json.loads(x)\n",
    "        dct = {k: [v] for k, v in dct.items()}\n",
    "        subrecord = pd.DataFrame().from_dict(dct)\n",
    "        records.append(subrecord)\n",
    "    df = pd.concat(records, axis=0)\n",
    "    df.columns = [original_name, suburb + ' (%)', 'New South Wales (%)', 'Australia (%)',\n",
    "                  suburb, 'New South Wales', 'Australia']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is consistent that we need to parse table 4 to table 39 for all 4 years.\n",
    "\n",
    "### Parse common tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commontables = {}\n",
    "\n",
    "errortables = None\n",
    "dataroot = 'census_data'\n",
    "if not os.path.exists(dataroot):\n",
    "    os.mkdir(dataroot)\n",
    "    \n",
    "for year in ['2001', '2006', '2011', '2016']: \n",
    "    # open pickle file\n",
    "    with open('source{}.pkl'.format(year), 'rb') as f:\n",
    "        source = pickle.load(f)\n",
    "    \n",
    "    # iterate all common tables\n",
    "    for index, tablename in common_map[year].items():\n",
    "        path = os.path.join(dataroot, '{}_{}.csv'.format(year, tablename).replace(' ', '_'))\n",
    "        print('Year={} Table={}'.format(year, tablename))\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "        group = []\n",
    "        for i, (suburb, txt) in enumerate(source.items()):\n",
    "            if i % 100 == 0:\n",
    "                print('    Iteration i={}'.format(i))\n",
    "            soup = bs(txt, 'html')\n",
    "            # find all tables\n",
    "            tables = soup.find_all('table')\n",
    "            try:\n",
    "                sdata = parse_common_table(tables[index], year)\n",
    "                group.append(sdata)\n",
    "            except IndexError:\n",
    "                print('  Error with {}, index={}'.format(suburb, index))\n",
    "                errortables = tables\n",
    "                break\n",
    "            \n",
    "        df = pd.concat(group, axis=0).drop_duplicates()\n",
    "        print('Saving to', path)\n",
    "        df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Family composition</th>\n",
       "      <th>Couple family without children</th>\n",
       "      <th>Couple family with children</th>\n",
       "      <th>One parent family</th>\n",
       "      <th>Other family</th>\n",
       "      <th>Total families</th>\n",
       "      <th>Couple family without children (%)</th>\n",
       "      <th>Couple family with children (%)</th>\n",
       "      <th>One parent family (%)</th>\n",
       "      <th>Other family (%)</th>\n",
       "      <th>Total families (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbotsbury</th>\n",
       "      <td>200</td>\n",
       "      <td>774</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>1108</td>\n",
       "      <td>18.1</td>\n",
       "      <td>69.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1.94364e+06</td>\n",
       "      <td>2.36258e+06</td>\n",
       "      <td>823254</td>\n",
       "      <td>89686</td>\n",
       "      <td>5.21916e+06</td>\n",
       "      <td>37.2</td>\n",
       "      <td>45.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Family composition Couple family without children Couple family with children  \\\n",
       "Abbotsbury                                    200                         774   \n",
       "Australia                             1.94364e+06                 2.36258e+06   \n",
       "\n",
       "Family composition One parent family Other family Total families  \\\n",
       "Abbotsbury                       127            7           1108   \n",
       "Australia                     823254        89686    5.21916e+06   \n",
       "\n",
       "Family composition Couple family without children (%)  \\\n",
       "Abbotsbury                                       18.1   \n",
       "Australia                                        37.2   \n",
       "\n",
       "Family composition Couple family with children (%) One parent family (%)  \\\n",
       "Abbotsbury                                    69.9                  11.5   \n",
       "Australia                                     45.3                  15.8   \n",
       "\n",
       "Family composition Other family (%) Total families (%)  \n",
       "Abbotsbury                      0.6                 --  \n",
       "Australia                       1.7                 --  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Median weekly incomes</th>\n",
       "      <th>Personal</th>\n",
       "      <th>Family</th>\n",
       "      <th>Household</th>\n",
       "      <th>Personal (%)</th>\n",
       "      <th>Family (%)</th>\n",
       "      <th>Household (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Burwood</th>\n",
       "      <td>370</td>\n",
       "      <td>1115</td>\n",
       "      <td>1005</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>466</td>\n",
       "      <td>1171</td>\n",
       "      <td>1027</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Median weekly incomes Personal Family Household Personal (%) Family (%)  \\\n",
       "Burwood                    370   1115      1005           --         --   \n",
       "Australia                  466   1171      1027           --         --   \n",
       "\n",
       "Median weekly incomes Household (%)  \n",
       "Burwood                          --  \n",
       "Australia                        --  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = tables[4]\n",
    "# tables[4]\n",
    "\n",
    "table = tables[4]\n",
    "\n",
    "# find column names\n",
    "row = table.find_all('tr')[0]\n",
    "columns = [x.text for x in row.find_all('th')]\n",
    "for i, x in enumerate(columns):\n",
    "    if x == '%':\n",
    "        columns[i] = columns[i - 1] + \" (%)\"\n",
    "columns\n",
    "\n",
    "values = get_values_2006(table)\n",
    "\n",
    "values\n",
    "\n",
    "data = pd.DataFrame(values, columns=columns).T\n",
    "data.columns = data.iloc[0]\n",
    "data = data.iloc[1:]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'text/javascript'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts = soup.find_all('script')\n",
    "scripts[9].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "javascript = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs\n",
    "              and x.attrs['type'] == 'text/javascript'][0]\n",
    "\n",
    "# javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.compile(\"var ancestryData = \\[\\];\").findall(javascript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21260.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(people.find_all('td')[1].text.replace(',', ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
