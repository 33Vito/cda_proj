{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pickle\n",
    "import matplotlib.pyplot as pl\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(val):\n",
    "    \"\"\"Convert a value to numeric if it is.\"\"\"\n",
    "    val = val.replace(',', '')\n",
    "    val = float(val) if val.isdigit() else val\n",
    "    return val\n",
    "\n",
    "def get_values_2006(table):\n",
    "    \"\"\"Parse table for 2006 html page.\"\"\"\n",
    "    # find values\n",
    "    values = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        if row.find('td') is None:\n",
    "            continue\n",
    "        record = [row.find_all('td')[0].text]\n",
    "        records = record + [convert(x.text) for x in row.find_all('td')[1:]]\n",
    "        if len(records) == 1:\n",
    "            continue\n",
    "        values.append(records)\n",
    "    return values\n",
    "\n",
    "def get_values_2016(table):\n",
    "    \"\"\"Parse table for 2016 html page.\"\"\"\n",
    "    # find values\n",
    "    values = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        if row.find('td') is None:\n",
    "            continue\n",
    "        record = [row.find_all('th')[0].text]\n",
    "        records = record + [convert(x.text) for x in row.find_all('td')]\n",
    "        values.append(records)\n",
    "    return values\n",
    "\n",
    "def parse_common_table(table, year):\n",
    "    \"\"\"Parse table that has common row names across different suburbs.\"\"\"\n",
    "    # find column names\n",
    "    row = table.find_all('tr')[0]\n",
    "    columns = [x.text for x in row.find_all('th')]\n",
    "    for i, x in enumerate(columns):\n",
    "        if x == '%':\n",
    "            columns[i] = columns[i - 1] + \" (%)\"\n",
    "    \n",
    "    if year != '2016':\n",
    "        values = get_values_2006(table)\n",
    "    else:\n",
    "        values = get_values_2016(table)\n",
    "    \n",
    "    data = pd.DataFrame(values, columns=columns).T\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.iloc[1:]\n",
    "\n",
    "    # create double columns for percentage\n",
    "    columns = list(data.columns)\n",
    "    newcolumns = [x + ' (%)' for x in columns]\n",
    "    for x in newcolumns:\n",
    "        data[x] = None\n",
    "        \n",
    "    # find percentage rows and fill in value\n",
    "    index = [x for x in data.index if '%' in x]\n",
    "    for i in index:\n",
    "        record = data.loc[i]\n",
    "        rowname = ' '.join(i.split(' ')[:-1])\n",
    "        for x in columns:\n",
    "            data.at[rowname, x + ' (%)'] =  record[x]\n",
    "    \n",
    "    # drop those rows\n",
    "    data = data.drop(index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_map = {}\n",
    "uncommon_map = {}\n",
    "\n",
    "for year in ['2001', '2006', '2011', '2016']:\n",
    "    with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    soup = bs(d['Burwood'], 'html')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    cmap = {}\n",
    "    ucmap = {}\n",
    "    for i, tb in enumerate(tables):\n",
    "        try:\n",
    "            z = re.search(r'(\\<\\!--).+(-->)', str(tb))\n",
    "            name = z.group().replace('<!-- ', '').replace('-->', '').strip()\n",
    "        except AttributeError:\n",
    "            name = tb.text.strip().split('\\n')[0]\n",
    "        try:\n",
    "            df = parse_common_table(tb, year)\n",
    "            if len(df.columns) <= 1:\n",
    "                ucmap[i] = name\n",
    "            else:\n",
    "                cmap[i] = name\n",
    "        except:\n",
    "            cmap[i] = name\n",
    "    # append to overall mapping\n",
    "    common_map[year] = cmap\n",
    "    uncommon_map[year] = ucmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2001': {9: 'Religious affiliation, top responses',\n",
       "  10: 'Language, top responses (other than English)',\n",
       "  12: 'Occupation',\n",
       "  13: 'Industry of employment, top responses',\n",
       "  8: 'Country of birth'},\n",
       " '2006': {9: 'Religious affiliation, top responses',\n",
       "  10: 'Language, top responses (other than English)',\n",
       "  12: 'Occupation',\n",
       "  13: 'Industry of employment, top responses',\n",
       "  21: 'Household composition',\n",
       "  8: 'Country of birth'},\n",
       " '2011': {11: 'Ancestry, top responses',\n",
       "  14: 'Religious affiliation, top responses',\n",
       "  15: 'Language, top responses (other than English)',\n",
       "  19: 'Occupation',\n",
       "  20: 'Industry of employment, top responses',\n",
       "  22: 'Travel to work, top responses',\n",
       "  12: 'Country of birth'},\n",
       " '2016': {9: 'Ancestry, top responses',\n",
       "  12: 'Country of birth of father',\n",
       "  13: 'Country of birth of mother',\n",
       "  14: 'Religious affiliation',\n",
       "  15: 'Language, top responses5',\n",
       "  18: 'Occupation',\n",
       "  19: 'Industry of employment',\n",
       "  21: 'Travel to work',\n",
       "  10: 'Country of birth'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non2016 = [0, 1, 2, 3, 4]\n",
    "yes2016 = [0, 1, 2, 3]\n",
    "for year in common_map:\n",
    "    exclusion = yes2016 if year == '2016' else non2016\n",
    "    common_map[year] = {k: v for k, v in common_map[year].items() if k not in exclusion and v != ''}\n",
    "    \n",
    "# country of birth should be taken out\n",
    "for year in common_map:\n",
    "    c = common_map[year]\n",
    "    topop = None\n",
    "    for k, v in c.items():\n",
    "        if v == 'Country of birth':\n",
    "            uncommon_map[year][k] = v\n",
    "            topop = k\n",
    "    common_map[year].pop(k)\n",
    "uncommon_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Industry of employment'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = '2016'\n",
    "with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "    source = pickle.load(f)\n",
    "uncommon_map\n",
    "uncommon_map[year]\n",
    "index = 6\n",
    "tablename = list(uncommon_map[year].values())[index]\n",
    "suburb = 'Burwood'\n",
    "\n",
    "soup = bs(source[suburb], 'html')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "tables[index]\n",
    "\n",
    "# find javascript\n",
    "scripts = soup.find_all('script')\n",
    "javascript = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs\n",
    "              and x.attrs['type'] == 'text/javascript'][0]\n",
    "tablename\n",
    "\n",
    "# uncommon_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Social marital statusPeople aged 15 years and over',\n",
       " 'Burwood (NSW)',\n",
       " 'Burwood (NSW) (%)',\n",
       " 'New South Wales',\n",
       " 'New South Wales (%)',\n",
       " 'Australia',\n",
       " 'Australia (%)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = tables[index]\n",
    "# find column names\n",
    "\n",
    "tables[index]\n",
    "\n",
    "# find javascript\n",
    "scripts = soup.find_all('script')\n",
    "javascript = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs\n",
    "              and x.attrs['type'] == 'text/javascript'][0]\n",
    "\n",
    "row = table.find_all('tr')[0]\n",
    "columns = [x.text for x in row.find_all('th')]\n",
    "for i, x in enumerate(columns):\n",
    "    if x == '%':\n",
    "        columns[i] = columns[i - 1] + \" (%)\"\n",
    "        \n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2001': {'Religious affiliation, top responses': 'var religiousAffiliationData',\n",
       "  'Language, top responses (other than English)': 'var languageData',\n",
       "  'Occupation': 'var occupationData',\n",
       "  'Industry of employment, top responses': 'var industryData',\n",
       "  'Country of birth': 'var countryOfBirthData'},\n",
       " '2006': {'Religious affiliation, top responses': 'var religiousAffiliationData',\n",
       "  'Language, top responses (other than English)': 'var languageData',\n",
       "  'Occupation': 'var occupationData',\n",
       "  'Industry of employment, top responses': 'var industryData',\n",
       "  'Household composition': 'var householdCompositionData',\n",
       "  'Country of birth': 'var countryOfBirthData'},\n",
       " '2011': {'Ancestry, top responses': 'var ancestryData',\n",
       "  'Religious affiliation, top responses': 'var religiousAffiliationData',\n",
       "  'Language, top responses (other than English)': 'var languageData',\n",
       "  'Occupation': 'var occupationData',\n",
       "  'Industry of employment, top responses': 'var industryData',\n",
       "  'Travel to work, top responses': 'var travelToWorkData',\n",
       "  'Country of birth': 'var countryOfBirthData'},\n",
       " '2016': {'Ancestry, top responses': 'var ancestryData',\n",
       "  'Country of birth of father': 'var countryOfFatherData',\n",
       "  'Country of birth of mother': 'var countryOfMotherData',\n",
       "  'Religious affiliation': 'var religiousAffiliationData',\n",
       "  'Language, top responses5': 'var languageData',\n",
       "  'Occupation': 'var occupationData',\n",
       "  'Industry of employment': 'var industryData',\n",
       "  'Travel to work': 'var travelToWorkData',\n",
       "  'Country of birth': 'var countryOfBirthData'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_mapping = {}\n",
    "\n",
    "for year in ['2001', '2006', '2011', '2016']:\n",
    "    p = {}\n",
    "    for _, k in uncommon_map[year].items():\n",
    "        newk = k.split(',')[0]\n",
    "        newk = newk.replace('birth of', '')\n",
    "        newk = newk.replace(' of employment', '')\n",
    "        newk = newk.split(' ')\n",
    "        if len(newk) > 1:\n",
    "            newk[1:] = [x.capitalize() for x in newk[1:]]\n",
    "        newk[0] = newk[0].lower()\n",
    "        newk = ''.join(newk)\n",
    "        p[k] = 'var {}Data'.format(newk)\n",
    "\n",
    "    pattern_mapping[year] = p\n",
    "\n",
    "pattern_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ancestry, top responses</th>\n",
       "      <th>Burwood (%)</th>\n",
       "      <th>New South Wales (%)</th>\n",
       "      <th>Australia (%)</th>\n",
       "      <th>Burwood</th>\n",
       "      <th>New South Wales</th>\n",
       "      <th>Australia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>45.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8,096</td>\n",
       "      <td>514,594</td>\n",
       "      <td>1,213,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1,248</td>\n",
       "      <td>2,302,481</td>\n",
       "      <td>7,852,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australian</td>\n",
       "      <td>5.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>944</td>\n",
       "      <td>2,261,062</td>\n",
       "      <td>7,298,243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>694</td>\n",
       "      <td>211,927</td>\n",
       "      <td>619,164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Korean</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>667</td>\n",
       "      <td>66,613</td>\n",
       "      <td>123,017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ancestry, top responses Burwood (%) New South Wales (%) Australia (%)  \\\n",
       "0                 Chinese        45.1                 5.2           3.9   \n",
       "0                 English         7.0                23.3          25.0   \n",
       "0              Australian         5.3                22.9          23.3   \n",
       "0                  Indian         3.9                 2.1           2.0   \n",
       "0                  Korean         3.7                 0.7           0.4   \n",
       "\n",
       "  Burwood New South Wales  Australia  \n",
       "0   8,096         514,594  1,213,903  \n",
       "0   1,248       2,302,481  7,852,224  \n",
       "0     944       2,261,062  7,298,243  \n",
       "0     694         211,927    619,164  \n",
       "0     667          66,613    123,017  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "var = list(p2016.values())[i]\n",
    "original_name = list(uncommon_map['2016'].values())[i]\n",
    "get_vardata(var, javascript, original_name, 'Burwood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Javascript Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year=2001 Table=Religious affiliation, top responses\n",
      "Year=2001 Table=Language, top responses (other than English)\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "    Iteration i=300\n",
      "    Iteration i=400\n",
      "    Iteration i=500\n",
      "    Iteration i=600\n",
      "    Iteration i=700\n",
      "Saving to census_data/2001_Language_top_responses_(other_than_English).csv\n",
      "Year=2001 Table=Occupation\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "    Iteration i=300\n",
      "    Iteration i=400\n",
      "    Iteration i=500\n",
      "    Iteration i=600\n",
      "    Iteration i=700\n",
      "Saving to census_data/2001_Occupation.csv\n",
      "Year=2001 Table=Industry of employment, top responses\n",
      "    Iteration i=0\n",
      "    Iteration i=100\n",
      "    Iteration i=200\n",
      "    Iteration i=300\n",
      "    Iteration i=400\n",
      "    Iteration i=500\n",
      "    Iteration i=600\n",
      "    Iteration i=700\n",
      "Saving to census_data/2001_Industry_of_employment_top_responses.csv\n",
      "Year=2001 Table=Country of birth\n"
     ]
    }
   ],
   "source": [
    "# year = '2001'\n",
    "dataroot = 'census_data'\n",
    "\n",
    "for year in ['2001']:\n",
    "    with open('source/source{}.pkl'.format(year), 'rb') as f:\n",
    "        source = pickle.load(f)\n",
    "\n",
    "    # iterate all common tables\n",
    "    for index, tablename in uncommon_map[year].items():\n",
    "        name = '{}_{}.csv'.format(year, tablename).replace(' ', '_').replace(',', '')\n",
    "        name = name.replace('/', '_')\n",
    "        path = os.path.join(dataroot, name)\n",
    "        print('Year={} Table={}'.format(year, tablename))\n",
    "        if os.path.exists(path):\n",
    "            continue\n",
    "        group = []\n",
    "        for i, (suburb, txt) in enumerate(source.items()):\n",
    "            if i % 100 == 0:\n",
    "                print('    Iteration i={}'.format(i))\n",
    "            soup = bs(txt, 'html')\n",
    "            try:\n",
    "                var = pattern_mapping[year][tablename]\n",
    "                if var not in txt:\n",
    "                    continue\n",
    "                sdata = parse_uncommon_table(soup, var, tablename, suburb, year)\n",
    "                group.append(sdata)\n",
    "            except IndexError:\n",
    "                print('  Error with {}, index={}'.format(suburb, index))\n",
    "                continue\n",
    "        try:\n",
    "            data = parse_uncommon_allsuburbs(group)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        print('Saving to', path)\n",
    "        data.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['New South Wales (%)', 'Australia (%)', 'New South Wales', 'Australia']\n",
    "def parse_uncommon_allsuburbs(group):\n",
    "    \"\"\"Parse uncommon table of all suburbs in group.\"\"\"\n",
    "    # drop NSW and Australia in 1: tables\n",
    "    for i, df in enumerate(group):\n",
    "        if i > 0:\n",
    "            for x in todrop:\n",
    "                if x in df:\n",
    "                    df = df.drop(x, axis=1)\n",
    "                    group[i] = df\n",
    "    # outer join all dataframes\n",
    "    key = group[0].columns[0]\n",
    "    data = pd.merge(group[0], group[1], how='outer', on=key)\n",
    "    for i in range(2, len(group)):\n",
    "        data = pd.merge(data, group[i], how='outer', on=key)\n",
    "    \n",
    "    # transpose and set column names\n",
    "    data = data.T\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.iloc[1:]\n",
    "\n",
    "    # create double columns for percentage\n",
    "    columns = list(data.columns)\n",
    "    newcolumns = [x + ' (%)' for x in columns]\n",
    "    for x in newcolumns:\n",
    "        data[x] = None\n",
    "\n",
    "    # find percentage rows and fill in value\n",
    "    index = [x for x in data.index if '%' in x]\n",
    "    for i in index:\n",
    "        record = data.loc[i]\n",
    "        rowname = ' '.join(i.split(' ')[:-1])\n",
    "        for x in columns:\n",
    "            data.at[rowname, x + ' (%)'] =  record[x]\n",
    "\n",
    "    # drop those rows\n",
    "    data = data.drop(index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "toaddquote1 = ['categoryField', 'areaPercent', 'statePercent', 'australiaPercent',\n",
    "              'areaValue', 'stateValue', 'australiaValue']\n",
    "toaddquote2 = ['categoryField', 'areaPercent', 'australiaPercent',\n",
    "              'areaValue', 'australiaValue']\n",
    "toremove = ['QuickStats.formatValue(', ')']\n",
    "\n",
    "def parse_uncommon_table(soup, var, original_name, suburb, year):\n",
    "    \"\"\"Get JS variable data from HTML.\"\"\"\n",
    "    # find javascript\n",
    "    scripts = soup.find_all('script')\n",
    "    js = [x for x in scripts if 'src' not in x.attrs and 'type' in x.attrs and x.attrs['type'] == 'text/javascript'][0]\n",
    "    # pattern name\n",
    "    pattern = '(' + var + ' = \\[)[^\\]]*(\\];)'\n",
    "    toreplace = var + ' = ['\n",
    "    m = re.search(pattern, str(js))\n",
    "    j = m.group().replace(toreplace, '').replace('];', '').strip()\n",
    "    j = j.replace('\\n', '').replace('\\t', '')\n",
    "\n",
    "    toaddquote = toaddquote1 if year == '2011' or year == '2016' else toaddquote2\n",
    "    for val in toaddquote:\n",
    "        j = j.replace(val, '\"{}\"'.format(val))\n",
    "\n",
    "    for val in toremove:\n",
    "        j = j.replace(val, '')\n",
    "\n",
    "    values = j.split('},')\n",
    "    values = [x + '}' for x in values]\n",
    "    values = [x.replace('}}', '}') for x in values if len(x) > 3]\n",
    "\n",
    "    records = []\n",
    "    for x in values:\n",
    "        try:\n",
    "            dct = json.loads(x)\n",
    "        except:\n",
    "#             print(x)\n",
    "            continue\n",
    "        dct = {k: [v] for k, v in dct.items()}\n",
    "        subrecord = pd.DataFrame().from_dict(dct)\n",
    "        records.append(subrecord)\n",
    "    df = pd.concat(records, axis=0)\n",
    "    if year == '2011' or year == '2016':\n",
    "        newcolumns = [original_name, suburb + ' (%)', 'New South Wales (%)', 'Australia (%)',\n",
    "                      suburb, 'New South Wales', 'Australia']\n",
    "    else:\n",
    "        newcolumns = [original_name, suburb + ' (%)', 'Australia (%)',\n",
    "                      suburb, 'Australia']\n",
    "    df.columns = newcolumns\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
